{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Input, Multiply, GlobalAveragePooling2D, Reshape, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²½ë¡œ ì„¤ì •\n",
    "train_metadata_path = os.path.expanduser('/2501ml_data/label/train_label.txt')\n",
    "test_metadata_path = os.path.expanduser('/2501ml_data/label/test_label.txt')\n",
    "train_data_path = os.path.expanduser('/2501ml_data/train')\n",
    "test_data_path = os.path.expanduser('/2501ml_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel-spectrogram ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_mel_spectrogram(file_path, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y[:48000], sr=sr, n_mels=n_mels)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    return log_mel_spec  # shape: (128, 94)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë”© í•¨ìˆ˜\n",
    "def load_dataset(metadata_path, data_path):\n",
    "    x_data, y_data = [], []\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        for line in f:\n",
    "            spk, file_name, _, _, label = line.strip().split(' ')\n",
    "            wav_path = os.path.join(data_path, file_name)\n",
    "            features = extract_mel_spectrogram(wav_path)\n",
    "            x_data.append(features)\n",
    "            y_data.append(label)\n",
    "    return np.array(x_data), np.array(y_data)\n",
    "\n",
    "\n",
    "# Mel-spectrogram ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_x, train_y = load_dataset(train_metadata_path, train_data_path)\n",
    "test_x, test_y = load_dataset(test_metadata_path, test_data_path)\n",
    "\n",
    "# ì±„ë„ ì°¨ì› ì¶”ê°€ â†’ (128, 400, 1)\n",
    "train_x = train_x[..., np.newaxis]\n",
    "test_x = test_x[..., np.newaxis]\n",
    "\n",
    "# ë¼ë²¨ ì¸ì½”ë”© + ì›-í•« ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_y)\n",
    "y_test = le.transform(test_y)\n",
    "\n",
    "y_train_oh = to_categorical(y_train)\n",
    "y_test_oh = to_categorical(y_test)\n",
    "\n",
    "# âœ… í™•ì¸\n",
    "print(\"train_x shape:\", train_x.shape)\n",
    "print(\"test_x shape:\", test_x.shape)\n",
    "print(\"y_train_oh shape:\", y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act='leaky_relu'\n",
    "\n",
    "def se_block(x, reduction=8):\n",
    "    channels = x.shape[-1]\n",
    "    se = GlobalAveragePooling2D()(x)\n",
    "    se = Dense(channels // reduction, activation='relu')(se)\n",
    "    se = Dense(channels, activation='sigmoid')(se)\n",
    "    se = Reshape((1, 1, channels))(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "def build_attention_cnn(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3,3), activation=act, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Conv Block 2\n",
    "    x = Conv2D(64, kernel_size=(3,3), activation=act, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Conv Block 3 (with attention)\n",
    "    x = Conv2D(128, kernel_size=(3,3), activation=act, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = se_block(x)  # attention ì¶”ê°€\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Conv Block 4 (with attention)\n",
    "    x = Conv2D(256, kernel_size=(3,3), activation=act, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = se_block(x)  # attention ì¶”ê°€\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=act)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# ì…ë ¥ í˜•íƒœ ë° í´ë˜ìŠ¤ ìˆ˜ ì„¤ì •\n",
    "input_shape = train_x.shape[1:]  # (128, 400, 1)\n",
    "num_classes = y_train_oh.shape[1]\n",
    "\n",
    "# 2ï¸ í›ˆë ¨/ê²€ì¦ ë¶„ë¦¬\n",
    "train_x_split, val_x, y_train_split, val_y = train_test_split(\n",
    "    train_x, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "# 3ï¸ ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼\n",
    "model = build_attention_cnn(input_shape)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4ï¸ ì½œë°± ì„¤ì •\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# 5ï¸ ëª¨ë¸ í•™ìŠµ\n",
    "history = model.fit(\n",
    "    train_x_split, y_train_split,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_x, val_y),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 6ï¸ ìµœì¢… í‰ê°€ (test set)\n",
    "loss, acc = model.evaluate(test_x, y_test, verbose=0)\n",
    "print(f\"\\n ìµœì¢… Test Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ì˜ˆì¸¡\n",
    "y_pred = model.predict(test_x)\n",
    "y_pred_classes = np.around(y_pred)\n",
    "# ì„±ëŠ¥ ì§€í‘œ ì¶œë ¥\n",
    "print(\"ğŸ“Š Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, target_names=le.classes_))\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
